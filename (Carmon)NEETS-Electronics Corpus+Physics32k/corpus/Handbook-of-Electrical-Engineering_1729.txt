maximum  amount  of  information.  From  the  point  of  view  of  a  human  or  machine  interpreter,  however,  it
contains no information at all. Irrelevancy refers to the fact that not all the information in the image is required
for  its  intended  application.  First,  under  typical  viewing  conditions,  it  is  possible  to  remove  some  of  the
information in an image without producing a change that is perceptible to a human observer. This is because
of  the  limited  ability  of  the  human  viewer  to  detect  small  changes  in  luminance  over  a  large  area  or  larger
changes in luminance over a very small area, especially in the presence of detail that may mask these changes.
Second, even though some degradation in image quality may be observed as a result of image compression,
the  degradation  may  not  be  objectionable  for  a  particular  application,  such  as  teleconferencing.  Third,  the
degradation introduced by image compression may not interfere with the ability of a human or machine to
extract  the  information  from  the  image  that  is  important  for  a  particular  application.  Lossless  compression
algorithms can only exploit redundancy, whereas lossy methods may exploit both redundancy and irrelevancy.
A myriad of approaches have been proposed for image compression. To bring some semblance of order to
the  ﬁeld,  it  is  helpful  to  identify  those  key  elements  that  provide  a  reasonably  accurate  description  of  most
encoding  algorithms.  These  are  shown  in  Fig. 17.6.  The  ﬁrst  step  is  feature  extraction.  Here  the  image  is
partitioned  into  N  3  N  blocks  of  pixels.  Within  each  block,  a  feature  vector  is  computed  which  is  used  to
represent all the pixels within that block. If the feature vector provides a complete description of the block, i.e.,
the block of pixel values can be determined exactly from the feature vector, then the feature is suitable for use
in a lossless compression algorithm. Otherwise, the algorithm will be lossy. For the simplest feature vector, we
let the block size N = 1 and take the pixel values to be the features. Another important example for N = 1 is
to  let  the  feature  be  the  error  in  the  prediction  of  the  pixel  value  based  on  the  values  of  neighboring  pixels
which have already been encoded and, hence, whose values would be known as the decoder. This feature forms
the  basis  for  predictive  encoding,  of  which  differential  pulse-code  modulation  (DPCM)  is  a  special  case.  For
larger size blocks, the most important example is to compute a two-dimensional (2-D) Fourier-like transform
of  the  block  of  pixels  and  to  use  the  N2  transform  coefﬁcients  as  the  feature  vector.  The  widely  used  Joint
Photographic Experts Group (JPEG) standard image coder is based on the discrete cosine transform (DCT)
with  a  block  size  of  N  =  8.  In  all  of  the  foregoing  examples,  the  block  of  pixel  values  can  be  reconstructed
exactly from the feature vector. In the last example, the inverse DCT is used. Hence, all these features may form
the basis for a lossless compression algorithm. A feature vector that does not provide a complete description
of the pixel block is a vector consisting of the mean and variance of the pixels within the block and an N 3  N
binary mask indicating whether or not each pixel exceeds the mean. From this vector, we can only reconstruct
an approximation to the original pixel block which has the same mean and variance as the original. This feature
is  the  basis  for  the  lossy  block  truncation  coding  algorithm.  Ideally,  the  feature  vector  should  be  chosen  to
provide as nonredundant as possible a representation of the image and to separate those aspects of the image
that are relevant to the viewer from those that are irrelevant.