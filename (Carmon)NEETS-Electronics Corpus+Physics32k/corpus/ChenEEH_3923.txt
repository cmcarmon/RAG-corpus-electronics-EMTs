The fundamental concept underlying the Fisher school of
statistics is that of likelihood function. In contrast, Bayesian
statistics is derived from conditional distributions, namely, the
a posteriori distributions. This section begins with an intro-
duction of the likelihood function and a derivation of the
maximum likelihood estimation method. These are followed
by the notion of sufﬁcient statistics, which plays an important
role in Fisherian statistics. Optimality properties of maximum
likelihood estimates are then examined with the deﬁnition of
Fisher information. Crame´r-Rao lower bound and minimum
variance unbiased estimators are then discussed.