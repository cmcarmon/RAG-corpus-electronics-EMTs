Level 1 represents systems that model raw video data using
features such as color histogram, shape and texture descrip-
tors, or trajectory of objects. This model can be used to serve a
query like ‘‘shots of object with dominant red color moving
from left corner to right.’’ CBVIR systems based on these
models operate directly on the data, employing techniques
from signal processing domain. Level 2 consists of derived or
logical features involving some degree of statistical and logical
inference about the identity of objects depicted by visual
media. An example query at this level can be ‘‘shots of Sears
Tower.’’ Using these models, systems normally operate on low-
level feature representation, though they can also use video
data directly. Level 3 deals with semantic abstractions involv-
ing a signiﬁcant amount of high-level reasoning about the
meaning and purpose of the objects or scenes depicted. An
example of a query at this level can be ‘‘shots depicting human
suffering or sorrow.’’ As indicated at level 3 of the ﬁgure, the AI
community has had the leading role in this effort. Systems at
this level can take semantic representation based on input
generated at level 2.