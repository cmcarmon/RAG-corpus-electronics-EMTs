The Unruh temperature, derived by William Unruh in 1976, is the effective temperature experienced by a uniformly accelerating detector in a vacuum field. It is given by




T
=



ℏ
a


2
π
c

k


B






,


{\displaystyle T={\frac {\hbar a}{2\pi ck_{\mathrm {B} }}},}

where a is the local acceleration, kB is the Boltzmann constant, ħ is the reduced Planck constant, and c is the speed of light. Thus, for example, a proper acceleration of 2.47×1020 m s−2 corresponds approximately to a temperature of 1 K. Conversely, an acceleration of 1 m/s2 corresponds to a temperature of 4.06×10−21 K.
The Unruh temperature has the same form as the Hawking temperature TH = ħg/2πckB of a black hole, which was derived (by Stephen Hawking) independently around the same time. It is, therefore, sometimes called the Hawking–Unruh temperature.