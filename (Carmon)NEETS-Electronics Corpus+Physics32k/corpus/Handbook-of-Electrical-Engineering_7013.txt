where I(X; Y) stands for the input-output mutual information, which is a measure of the dependence of the
input and the output deﬁned as the divergence between the joint input/output distribution and the product
of its marginals, D(PXY||PX PY). For any pair of probability mass functions P and Q deﬁned on the same space,
divergence is an asymmetric measure of their similarity: