A signal on a transmission line can become distorted even if the line constants, and the resulting transmission function, are all perfectly linear. There are two mechanisms: firstly, the attenuation of the line can vary with frequency which results in a change to the shape of a pulse transmitted down the line. Secondly, and usually more problematically, distortion is caused by a frequency dependence on phase velocity of the transmitted signal frequency components. If different frequency components of the signal are transmitted at different velocities the signal becomes "smeared out" in space and time, a form of distortion called dispersion.
This was a major problem on the first transatlantic telegraph cable and led to the theory of the causes of dispersion being investigated first by Lord Kelvin and then by Heaviside who discovered how it could be countered. Dispersion of telegraph pulses, if severe enough, will cause them to overlap with adjacent pulses, causing what is now called intersymbol interference. To prevent intersymbol interference it was necessary to reduce the transmission speed of the transatlantic telegraph cable to the equivalent of ​1⁄15 baud. This is an exceptionally slow data transmission rate, even for human operators who had great difficulty operating a morse key that slowly.
For voice circuits (telephone) the frequency response distortion is usually more important than dispersion whereas digital signals are highly susceptible to dispersion distortion. For any kind of analogue image transmission such as video or facsimile both kinds of distortion need to be eliminated.