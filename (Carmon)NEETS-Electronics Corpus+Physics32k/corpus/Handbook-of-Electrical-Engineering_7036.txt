Shannon  [1948]  was  the  ﬁrst  to  distinguish  the  probabilistic  model  that  underlies  an  information  source
from the semantics of the information. An information source produces one of many possible messages; the
goal of communication is to transmit an unambiguous speciﬁcation of the message so that the receiver can
reconstruct the original message. For example, the information to be sent may be the result of a horse race. If
the recipient is assumed to know the names and numbers of the horses, then all that must be transmitted is
the  number  of  the  horse  that  won.  In  a  different  context,  the  same  number  might  mean  something  quite
different, e.g., the price of a barrel of oil. The signiﬁcant fact is that the difﬁculty in communication depends
only  on  the  length  of  the  representation.  Thus,  ﬁnding  the  best  (shortest)  representation  of  an  information
source is critical to efﬁcient communication.