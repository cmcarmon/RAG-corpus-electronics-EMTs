The dynamical system concept is a mathematical formalization for any fixed "rule" that describes the time dependence of a point's position in its ambient space. Examples include the mathematical models that describe the swinging of a clock pendulum, the flow of water in a pipe, and the number of fish each spring in a lake.
A dynamical system has a state determined by a collection of real numbers, or more generally by a set of points in an appropriate state space. Small changes in the state of the system correspond to small changes in the numbers. The numbers are also the coordinates of a geometrical spaceâ€”a manifold. The evolution rule of the dynamical system is a fixed rule that describes what future states follow from the current state. The rule may be deterministic (for a given time interval only one future state follows from the current state) or stochastic (the evolution of the state is subject to random shocks).