In the theory of dynamical systems, a state variable in a system is said to be unstable if it evolves without bounds. A system itself is said to be unstable if at least one of its state variables is unstable.
In continuous time control theory, a system is unstable if any of the roots of its characteristic equation has real part greater than zero (or if zero is a repeated root). This is equivalent to any of the eigenvalues of the state matrix having either real part greater than zero, or, for the eigenvalues on the imaginary axis, the algebraic multiplicity being larger than the geometric multiplicity. The equivalent condition in discrete time is that at least one of the eigenvalues is greater than 1 in absolute value, or that two or more eigenvalues are equal and of unit absolute value.