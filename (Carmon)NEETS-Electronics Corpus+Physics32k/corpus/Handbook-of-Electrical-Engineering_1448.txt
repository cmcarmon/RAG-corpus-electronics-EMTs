Speech recognition by machine has proven an extremely difÔ¨Åcult task. One complicating factor is that, unlike
written  text,  no  clear  spacing  exists  between  spoken  words;  speakers  typically  utter  full  phrases  or  sentences
without  pause.  Furthermore,  acoustic  variability  in  the  speech  signal  typically  precludes  an  unambiguous
mapping to a sequence of words or subword units, such as phones.1 One major source of variability in speech
is  coarticulation,  or  the  tendency  for  the  acoustic  characteristics  of  a  given  speech  sound  or  phone  to  differ
depending  upon  the  phonetic  context  in  which  it  is  produced.  Other  sources  of  acoustic  variability  include
differences in vocal-tract size, dialect, speaking rate, speaking style, and communication channel.