The hypothesis claims that visual illusions occur because the neural circuitry in our visual system evolves, by neural learning, to a system that makes very efficient interpretations of usual 3D scenes based in the emergence of simplified models in our brain that speed up the interpretation process but give rise to optical illusions in unusual situations. In this sense, the cognitive processes hypothesis can be considered a framework for an understanding of optical illusions as the signature of the empirical statistical way vision has evolved to solve the inverse problem.
Research indicates that 3D vision capabilities emerge and are learned jointly with the planning of movements. After a long process of learning, an internal representation of the world emerges that is well-adjusted to the perceived data coming from closer objects. The representation of distant objects near the horizon is less "adequate". In fact, it is not only the Moon that seems larger when we perceive it near the horizon. In a photo of a distant scene, all distant objects are perceived as smaller than when we observe them directly using our vision.
The retinal image is the main source driving vision but what we see is a "virtual" 3D representation of the scene in front of us. We don't see a physical image of the world; we see objects, and the physical world is not itself separated into objects. We see it according to the way our brain organizes it. The names, colours, usual shapes and other information about the things we see pop up instantaneously from our neural circuitry and influence the representation of the scene. We "see" the most relevant information about the elements of the best 3D image that our neural networks can produce. The illusions arise when the "judgments" implied in the unconscious analysis of the scene are in conflict with reasoned considerations about it.