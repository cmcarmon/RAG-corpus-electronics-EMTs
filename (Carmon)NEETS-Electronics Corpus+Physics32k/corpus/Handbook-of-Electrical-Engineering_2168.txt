Training-Focused TLN Architectures
The  appeal  of  the  focused  architecture  is  that  the  MLP  weights  can  be  still  adapted  with  back-propagation.
However, the input/output mapping produced by these networks is static. The input memory layer is bringing
in past input information to establish the value of the mapping.