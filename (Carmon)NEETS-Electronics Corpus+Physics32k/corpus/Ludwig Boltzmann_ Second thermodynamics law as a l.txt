The idea that the second law of thermodynamics or "entropy law" is a law of disorder (or that dynamically ordered states are "infinitely improbable") is due to Boltzmann's view of the second law of thermodynamics.
In particular, it was Boltzmann's attempt to reduce it to a stochastic collision function, or law of probability following from the random collisions of mechanical particles. Following Maxwell, Boltzmann modeled gas molecules as colliding billiard balls in a box, noting that with each collision nonequilibrium velocity distributions (groups of molecules moving at the same speed and in the same direction) would become increasingly disordered leading to a final state of macroscopic uniformity and maximum microscopic disorder or the state of maximum entropy (where the macroscopic uniformity corresponds to the obliteration of all field potentials or gradients). The second law, he argued, was thus simply the result of the fact that in a world of mechanically colliding particles disordered states are the most probable. Because there are so many more possible disordered states than ordered ones, a system will almost always be found either in the state of maximum disorder – the macrostate with the greatest number of accessible microstates such as a gas in a box at equilibrium – or moving towards it. A dynamically ordered state, one with molecules moving "at the same speed and in the same direction", Boltzmann concluded, is thus "the most improbable case conceivable...an infinitely improbable configuration of energy."
Boltzmann accomplished the feat of showing that the second law of thermodynamics is only a statistical fact. The gradual disordering of energy is analogous to the disordering of an initially ordered pack of cards under repeated shuffling, and just as the cards will finally return to their original order if shuffled a gigantic number of times, so the entire universe must some-day regain, by pure chance, the state from which it first set out. (This optimistic coda to the idea of the dying universe becomes somewhat muted when one attempts to estimate the timeline which will probably elapse before it spontaneously occurs.) The tendency for entropy increase seems to cause difficulty to beginners in thermodynamics, but is easy to understand from the standpoint of the theory of probability. Consider two ordinary dice, with both sixes face up. After the dice are shaken, the chance of finding these two sixes face up is small (1 in 36); thus one can say that the random motion (the agitation) of the dice, like the chaotic collisions of molecules because of thermal energy, causes the less probable state to change to one that is more probable. With millions of dice, like the millions of atoms involved in thermodynamic calculations, the probability of their all being sixes becomes so vanishingly small that the system must move to one of the more probable states. However, mathematically the odds of all the dice results not being a pair sixes is also as hard as the ones of all of them being sixes, and since statistically the data tend to balance, one in every 36 pairs of dice will tend to be a pair of sixes, and the cards -when shuffled- will sometimes present a certain temporary sequence order even if in its whole the deck was disordered.